<!DOCTYPE html>
<html lang="en">
<head>
	<title>Shankhya Debnath </title>
  	<meta charset="utf-8">
  	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta charset="UTF-8">
  	<meta name="description" content="Shankhya Debnath">
  	<meta name="keywords" content="Shankhya Debnath">
  	<meta name="author" content="Shankhya Debnath">
	<meta name="msvalidate.01" content="DC94E1683197E154758452EFDE4EC02A" />
	<link rel="icon" href="images/icon.png" type="image/x-icon">

	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
  	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
  	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  	<link rel="stylesheet" href="css/academicons-1.8.0/css/academicons.css">
	<link rel="stylesheet" href="css/layout.css">

	
    <script>
        function toggleContent(button) {
            var content = button.previousElementSibling; // The content div
            if (content.classList.contains("expanded")) {
                content.classList.remove("expanded");
                button.textContent = "See more...";
            } else {
                content.classList.add("expanded");
                button.textContent = "See less...";
            }
        }
    </script>

    <style>
        .collapsible-content {
            max-height: 100px;
            overflow: hidden;
            transition: max-height 0.3s ease;
        }

        .collapsible-content.expanded {
            max-height: 1000px; /* Adjust to allow enough space for all content */
        }
    </style>

</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-Z6NX48XKRL"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-Z6NX48XKRL');
</script>
	
<body>
	<nav class="navbar navbar-inverse navbar-fixed-top">
		<div class="container-fluid">
			<div class="navbar-header">
				<button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
				</button>
			</div>
			<div class="collapse navbar-collapse" id="myNavbar">
				<ul class="nav navbar-nav">
					<li><a href="index.html"><i class="fa fa-home" aria-hidden="true"></i> Home</a></li>
					<li><a href="research.html"><i class="fa fa-graduation-cap" aria-hidden="true"></i> Research</a></li>
					<li><a href="publications.html"><i class="fa fa-book" aria-hidden="true"></i> Publications</a></li>
					<li><a href="students.html"><i class="fa fa-users" aria-hidden="true"></i> Students section</a></li>
					<li><a href="resources.html"><i class="fa fa-lightbulb-o" aria-hidden="true"></i> Resources</a></li>
					<li><a href="teaching.html"><i class="fa fa-graduation-cap" aria-hidden="true"></i> Teaching</a></li>
            		<li><a href="media.html"><i class="fa fa-television" aria-hidden="true"></i> Media</a></li>
					<li class="active"><a href="musings.html"><i class="fa fa-grav" aria-hidden="true"></i> Musings</a></li>
				</ul>
			</div>
		</div>
	</nav>

	<div class="container">
		<div class="row info">
			<div class="col-sm-4" style="background-color:white;">
				<br />
				<ul class="info">
					<li><span class="glyphicon glyphicon glyphicon-user"></span> <b>Shankhya Debnath</b></li>
					<li><span class="glyphicon glyphicon glyphicon-briefcase"></span> HoD & Lecturer, Dept. of Printing Technology</li>
					<li><i class="fa fa-university" aria-hidden="true"></i> <a href="http://polytechnic.wbtetsd.gov.in/riptkolkata" target="_blank"><span style="color:black; text-decoration: underline;">Regional Institute of Printing Technology</span></a></li>
					<li><span class="glyphicon glyphicon-envelope"></span> <a href="mailto:shankhya@wbscte.ac.in" target="_top"><span style="color:black;">shankhya@wbscte.ac.in</span></a></li>
					<li ><span class="glyphicon glyphicon-phone-alt"></span> 03324146432 (O)</li>
				</ul>
				<hr style="width:80%;">
				<ul class="info">
    				<li>
    					<!-- ORCID Link -->
    					<a href="https://orcid.org/0000-0003-0832-8556" target="_blank">
       					<i class="fa fa-id-badge" aria-hidden="true"></i> ORCID
    					</a>&nbsp;&nbsp;

    					<!-- SCOPUS Link -->
    					<a href="https://www.scopus.com/inward/authorDetails.uri?authorID=56844915400&partnerID=5ESL7QZV&md5=05fbf41f83b7057b1788f4307c864823" target="_blank">
        					<i class="fa fa-database" aria-hidden="true"></i> SCOPUS
   						</a>&nbsp;&nbsp;

					<!-- LinkedIn Link with Font Awesome Icon -->
    					<a href="http://www.linkedin.com/in/shankhya-debnath-624b0753" target="_blank">
        					<i class="fa fa-linkedin" aria-hidden="true"></i> LinkedIn
    					</a>&nbsp;&nbsp;

					<!-- Google Scholar Link with Font Awesome Icon -->
        					<a href="https://scholar.google.com/citations?user=VZpBk5kAAAAJ&hl=en" target="_blank">
            					<i class="fa fa-graduation-cap" aria-hidden="true"></i> Scholar
        					</a>&nbsp;&nbsp;
    				</li>
				</ul>
			</div>
			<div class="col-sm-8" style="background-color:white;padding:0px;">
				<img class="img-responsive img-rounded image1" src="images/bg.png" alt="background" width="100%">
				<img class="image2 img-rounded" src="images/image.jpg" alt="Name">
			</div>
		</div>

		<div class="row">
			<div class="col-sm-9 bio-section" style="background-color:white;padding:2%;">
				<h2><i class="fa fa-lightbulb-o" aria-hidden="true"></i> Musings</h2>
				<p style="text-align: justify;">
				    I am deeply interested in the field of color science, colorimetry and color management. However, I am not a coder and 
				the codes that I have used to solve problems I find interesting, may reflect my deficiency of coding skill.
				As a novice and a learner in the field of color science, I think however, that the topics I have written about and the
				codes I have created may work as a starting point for someone like me how shares the same passion and interest in the domain.
				Albeit some problems and solutions I have talked about here may seem trivial, but I feel that for understanding any field,
				one must have a very strong understanding of the basics. I am a firm believer of open science and free and open
				source software. As a learner, I feel that knowledge can not be bound and kept behind paywalls. And so I have given all 
				my source code with each post made in this page. I am hopeful that someone who shares my passion and philosophy
				may find some value in what I have shared.
				</p>
				<hr>

				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>16.08.2025</b>: SCIELAB Local Color-Difference Demo</h3>
				<div class="collapsible-content">
					<p align="justify">
					  The presented method describes a SCIELAB-inspired local color-difference demonstration. The goal is to combine color-difference metrics (e.g., CIEDE2000 or Euclidean CIELAB) with a multi-scale spatial integration to better approximate perceived differences in images. The document includes background theory, a mathematical description of the simplified SCIELAB-like pipeline implemented, results on test distortions, and interpretation of the outcomes.	<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/scielab.py" target="_blank">Source code</a> |
					    <a href="/musings/scielab.pdf" target="_blank">Mathematical background</a> 
					    
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/scielab.jpeg" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Mean luminance and luminance contrast for original and processed images.</figcaption>
					            </figure>
					        
					    </div>

					    

					  
					   
					</div>
					</div>
					<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>

				
				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>16.08.2025</b>: A Simplified iCAM-like Image Appearance Pipeline</h3>
				<div class="collapsible-content">
					<p align="justify">
					  This method describes the design, mathematical formulation, implementation, and experimental evaluation of a simplified iCAM-like image appearance pipeline. The pipeline implements the core appearance-preserving ideas from iCAM family models: (1) local adaptation estimation, (2) local tone mapping, and (3) chromatic preservation during luminance remapping. Results and quantitative summaries for example images are presented, followed by discussion on limitations and next steps for a closer reproduction of iCAM.</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/icam.py" target="_blank">Source code</a> |
					    <a href="/musings/icam02.pdf" target="_blank">Mathematical background</a> 
					    
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/icam02.jpeg" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Reference, distorted images, pixelwise ΔE maps, SCIELAB-like maps, and a zoomed crop comparison.</figcaption>
					            </figure>
					        
					    </div>

					    

					  
					   
					</div>
					</div>
					<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>

				
				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>16.08.2025</b>: CIECAM02 Implementation and Visualization</h3>
				<div class="collapsible-content">
					<p align="justify">
					  This method presents a basic implementation of the CIECAM02 color appearance model and a visualization study showing how a palette of colors behaves under different viewing conditions. The document contains necessary background, detailed mathematical descriptions of the model components used in the implementation, implementation notes, the visual results produced by the demo, and interpretations and inferences drawn from those results.
					</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/ciecam02_vis.py" target="_blank">Source code</a> |
					    <a href="/musings/CIECAM02_vis.pdf" target="_blank">Mathematical background</a> 
					    
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/ciecam02patch.jpeg" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">CIECAM02 palette</figcaption>
					            </figure>
					        
					    </div>

					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/jvsc.jpeg" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">J vs C for palette under different viewing conditions</figcaption>
					            </figure>
					        
					    </div>

					  
					   
					</div>
					</div>
					<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>

				

				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>06.10.2024</b>: Methods for Printer Calibration and Characterization</h3>
				<div class="collapsible-content">
					<p align="justify">
					  Methods for Channel-Independent Calibration, Cellular N-Model, Forward Characterization, and Inverse Characterization are presented. 
					The Channel-Independent Calibration focuses on calibrating each color channel independently by calculating and scaling color differences. 
					The Cellular N-Model addresses the interaction between colorants through trilinear interpolation and regression to optimize Neugebauer primaries. 
					Forward Characterization predicts color appearance based on CMYK input values, while Inverse Characterization inverts this process to find CMYK values 
					that achieve specific colorimetric targets. 
					</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/refs/heads/main/musings/chan_ind_cal.py" target="_blank">Channel Independent Calibration</a> |
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/refs/heads/main/musings/cell_n.py" target="_blank">Cellular Neugebauer based Characterization</a> |
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/refs/heads/main/musings/for_char.py" target="_blank">Empirical based Forward Characterization</a> |
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/refs/heads/main/musings/inv_char.py" target="_blank">Empirical based Inverse Characterization</a> |
					 <a href="/musings/print_char.pdf" target="_blank">Explanation</a> 
					
					    
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/cal.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Channel Independent Calibration</figcaption>
					            </figure>
					        
					    </div>
					    <div class="col-sm-6">
					        <figure>
					            <img src="musings/cell_n.png" class="img-responsive img-rounded" alt="Image 4">
					            <figcaption style="text-align: center;">YN Factor and N-primaries</figcaption>
					        </figure>
					    </div>
						
					</div>

					 <!-- Centered, larger third image -->
   					 <div class="row" style="padding: 2%; text-align: center;">
        					<div class="col-sm-12">
            					<figure>
                				<img src="musings/for_char.png" class="img-responsive img-rounded" style="max-width: 80%;" alt="Image 5">
                				<figcaption style="text-align: center;">Forward characterization</figcaption>
            					</figure>
        					</div>
						 <div class="col-sm-6">
					        <figure>
					            <img src="musings/inv_char.png" class="img-responsive img-rounded" alt="Image 4">
					            <figcaption style="text-align: center;">Inverses Characterization</figcaption>
					        </figure>
					    </div>
    					</div>
					</div>
					<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>



				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>20.09.2024</b>: Implementing modified convex hull for GBD computation</h3>
				<div class="collapsible-content">
					<p align="justify">
					  The presented method calculates and visualizes the Gamut Boundary Descriptor (GBD) in LAB color space using a modified convex hull 
					approach adapted from <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/3018/0000/Method-for-quantifying-the-color-gamut-of-an-output-device/10.1117/12.271580.short#_=_" target="_blank">Bala et. al</a>. It first converts the input image to LAB space, then applies a pre-conditioning transformation to adjust the 
					distance of each point from a reference point (typically [50, 0, 0]). The LAB space is segmented into bins based on 
					spherical coordinates, and the point with the maximum radial distance in each bin is selected as the segment maxima. 
					After applying a convex hull to these maxima points, an inverse transformation returns the points to LAB space, and the 
					resulting 3D surface is visualized. The granularity of the convex hull and size of the triangles can be adjusted by 
					increasing the segmentation bins, making the surface more detailed and precise.
					</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/gbd/smgbd_conv_hull.py" target="_blank">Source code</a> |
					    <a href="/musings/gbd/smgbd_ch.pdf" target="_blank">Mathematical background</a> 
					    
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/gbd/smgbd_conv_hull.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">GBD based on modified convex hull for Lena</figcaption>
					            </figure>
					        
					    </div>

					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/gbd/gbd_fogra39.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">GBD based on modified convex hull for FOGRA39 dataset</figcaption>
					            </figure>
					        
					    </div>

					  
					   
					</div>
					</div>
					<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>


				
				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>18.09.2024</b>: Predicting Perceptual Attributes Using Neural Networks</h3>
				<div class="collapsible-content">
					<p align="justify">
					  A method is proposed to predict perceptual color attributes (such as lightness, chroma, hue, etc.) based on spectral reflectance 
				data of color patches under various viewing conditions using a neural network. A 
					neural network is trained using the Munsell color patches under different illuminants, luminance levels, and background conditions. 
					The CIECAM02 color appearance model is employed to simulate how these color patches would appear under specific viewing conditions.
					</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/spectral/nncam.py" target="_blank">Source code</a> |
					    <a href="/musings/spectral/nncam.pdf" target="_blank">Mathematical background</a> 
					    
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/spectral/loss.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Loss plot for the trained model</figcaption>
					            </figure>
					        
					    </div>

					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/spectral/J.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Actual v/s predicted J</figcaption>
					            </figure>
					        
					    </div>
					   
					</div>
					</div>
					<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>

				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>14.09.2024</b>: A sigmoidal gamut compression algorithm</h3>
				<div class="collapsible-content">
					<p align="justify">
					  The presented method performs a gamut compression process on an image. It calculates the chroma and lightness 
					boundaries of the CMYK printer gamut and then applies a sigmoidal compression to the image's chroma and lightness values. 
					This ensures that all colors fit within the CMYK printer gamut, preventing out-of-gamut colors. The compressed image is 
					then reconstructed and displayed side-by-side with the original. Additionally, convex hulls of the original, compressed, 
					and CMYK gamuts are plotted in 3D to visualize the color space reduction, with the compressed gamut fitting entirely within 
					the CMYK gamut. The volumes of each gamut are also calculated to quantify the reduction in color space. A Delta E 2000 of 3.93
					is obtained between original and gamut compressed images.
					</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/gamut_mapping/sgcm.py" target="_blank">Source code</a> |
					    <a href="/musings/gamut_mapping/sgcm.pdf" target="_blank">Mathematical background</a> 
					    
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/gamut_mapping/scgm_comparison.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Gamut comparison</figcaption>
					            </figure>
					        
					    </div>

					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/gamut_mapping/sgcm_image.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Comparison of original and gamut compressed images</figcaption>
					            </figure>
					        
					    </div>
					   
					</div>
					</div>
					<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>


				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>13.09.2024</b>: Spectral Reconstruction from LAB Data Using Neural Networks</h3>
				<div class="collapsible-content">
					<p align="justify">
					  A method that implements a machine learning model using a neural network to perform spectral reconstruction from 
					LAB color values has been presented. It processes a dataset of color samples by first cleaning and filtering the data, then extracting 
					spectral reflectance values for 39 wavelengths. The neural network consists of an input layer for the LAB values, 
					followed by three hidden layers with ReLU activation, and an output layer that predicts the spectral values. The LAB 
					inputs and spectral outputs are standardized for efficient training. The model is compiled using the Adam optimizer 
					and the mean squared error (MSE) loss function. After training the model on the data, its performance is evaluated using 
					metrics like MSE, MAPE, and R². The trained model is then used to predict spectral reflectance for new samples, with the 
					actual and predicted spectra plotted for comparison. Results indicate that further investigation is required to ensure 
						generalization of the model and prevent overfitting.
					</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/spectral/spectral_recon.py" target="_blank">Source code</a> |
					    <a href="/musings/spectral/spectral_recons.pdf" target="_blank">Mathematical background</a> 
					    
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/spectral/loss.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Model loss plot</figcaption>
					            </figure>
					        
					    </div>

					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/spectral/predicted_spectra.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Comparison of predicted spectra against actual spectra for 20 randomly selected samples</figcaption>
					            </figure>
					        
					    </div>
					   
					</div>
					</div>
					<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>


				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>10.09.2024</b>: A method for Gamut Compression towards L=50</h3>
				<div class="collapsible-content">
					<p align="justify">
					  This method involves compressing an image's RGB gamut to fit within the smaller CMYK device gamut. Out-of-gamut 
					colors in the RGB space are compressed by mapping them to the nearest boundary point of the CMYK gamut, while in-gamut 
					colors are proportionally compressed towards a target lightness value of 𝐿∗=50. This ensures that all colors fit 
					within the CMYK space while preserving the image’s overall lightness and reducing chroma. A DeltaE2000 of 6.1366 is obtained
					between original and gamut compressed images.
					</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/gamut_mapping/gamut_comp.py" target="_blank">Source code</a> |
					    <a href="/musings/gamut_mapping/gamut_comp.pdf" target="_blank">Mathematical background</a> 
					    
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/gamut_mapping/gamut_comp.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Gamut comparison after compression</figcaption>
					            </figure>
					        
					    </div>

					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/gamut_mapping/gamut_comp_image.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Comparison of original and gamut compressed images</figcaption>
					            </figure>
					        
					    </div>
					   
					</div>
					</div>
					<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>


				
				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>09.09.2024</b>: A method to implement nearest neighbor gamut clipping</h3>
				<div class="collapsible-content">
					<p align="justify">
					   A nearest neighbor gamut clipping where an RGB image is transformed to fit within the CMYK gamut, 
					specifically using the Fogra39 dataset is presented. The process converts the image from RGB to the perceptually uniform 
					LAB and LCH color spaces. A convex hull is then computed for both the RGB image and the CMYK (Fogra39) dataset in the LCH 
					color space. Any colors in the RGB image that fall outside the CMYK gamut are mapped to their nearest neighbor on the 
					boundary of the CMYK convex hull using Euclidean distance.  
					The clipped LCH values are then converted back to LAB and subsequently to RGB for image reconstruction. The results show 
					that the clipped image retains most of its original appearance, but with some desaturation, particularly in highly saturated 
					colors, which is a natural consequence of fitting a broader RGB color space into the narrower CMYK gamut. A Delta E 2000 value
					of 2.2723 is obtained.
					</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/gamut_mapping/gamut_clip.py" target="_blank">Source code</a> |
					    <a href="/musings/gamut_mapping/gamut_clip.pdf" target="_blank">Mathematical background</a> 
					    
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/gamut_mapping/gamut_comparison.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Image and CMYK device gamuts</figcaption>
					            </figure>
					        
					    </div>
					    <div class="col-sm-6">
					        <figure>
					            <img src="musings/gamut_mapping/clipped_gamut.png" class="img-responsive img-rounded" alt="Image 4">
					            <figcaption style="text-align: center;">Image gamut clipped to device gamut</figcaption>
					        </figure>
					    </div>
						
					</div>

					 <!-- Centered, larger third image -->
   					 <div class="row" style="padding: 2%; text-align: center;">
        					<div class="col-sm-12">
            					<figure>
                				<img src="musings/gamut_mapping/clipped.png" class="img-responsive img-rounded" style="max-width: 80%;" alt="Image 5">
                				<figcaption style="text-align: center;">Comparison of original and gamut clipped images</figcaption>
            					</figure>
        					</div>
    					</div>
					</div>
					<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>


				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>04.09.2024</b>: A method for transforming tristimulus value to perceptual correlates using CIECAM models</h3>
				<div class="collapsible-content">
					<p align="justify">
					  A method is presented that allows users to convert CIE XYZ tristimulus values into perceptual correlates using either the CIECAM16 or 
					CIECAM02 color appearance models. The code takes input from the user, including the test sample's XYZ values, the reference white's XYZ 
					values, adapting luminance, and background luminance, and computes key appearance attributes such as lightness, chroma, hue, saturation, 
					brightness, and colorfulness. Based on the user's choice of model (CIECAM16 or CIECAM02), the code applies the corresponding mathematical 
					transformations, including chromatic adaptation, non-linear compression, and opponent color dimension calculations, and returns the predicted 
					perceptual correlates for the given viewing conditions.
					</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/ciecam.py" target="_blank">Source code</a> |
					    <a href="/musings/ciecam.pdf" target="_blank">Mathematical background</a> 
					    
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/ciecam02.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Outputs from CIECAM02 model</figcaption>
					            </figure>
					        
					    </div>

					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/ciecam16.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Outputs from CIECAM16 model</figcaption>
					            </figure>
					        
					    </div>
					   
					</div>
					</div>
					<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>


				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>04.09.2024</b>: A method for visualizing the CIELAB space at constant lightness planes</h3>
				<div class="collapsible-content">
					<p align="justify">
					  A method is presented here that is designed to allow a user to explore and interact with the CIELAB color space.
						It allows users to specify a lightness value and interactively click on points in a 2D plot representing the a* and b* color axes. 
						The clicked points are annotated with their respective a* and b* coordinates. Once a specified number of points is selected, 
						the convex hull is drawn around these points, representing the boundary enclosing these selected colors in the CIELAB space.

					</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/cielab.py" target="_blank">Source code</a> |
					    <a href="/musings/cielab.pdf" target="_blank">Mathematical background</a> 
					    
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/cielab.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">CIELAB space at L*=50 plane</figcaption>
					            </figure>
					        
					    </div>

					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/cielabgamut.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">The color gamut obtained between 6 colors</figcaption>
					            </figure>
					        
					    </div>
					   
					</div>
					</div>
					<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>


				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>03.09.2024</b>: A method for plotting the gamut for multiple chromaticities</h3>
				<div class="collapsible-content">
					<p align="justify">
					  A method has been presented that creates the CIE 1931 chromaticity diagram and asks users for input on the number of 
						colors they would want to plot in the space. Given a fixed number of points, the method then computes the convex
						hull between them and returns the color gamut in the xy space enclosed by the colors.

					</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/cieplot.py" target="_blank">Source code</a> |
					    <a href="/musings/cieplot.pdf" target="_blank">Mathematical background</a> 
					    
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/cie.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">CIE 1931 chromaticity diagram</figcaption>
					            </figure>
					        
					    </div>

					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/ciegamut.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">The color gamut obtained between 6 colors</figcaption>
					            </figure>
					        
					    </div>
					   
					</div>
					</div>
					<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>


				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>02.09.2024</b>: Comparison of techniques for halftone printer characterization</h3>
				<div class="collapsible-content">
					<p align="justify">
					  A method has been presented that evaluates the accuracy of various interpolation techniques for the characterization of a half-tone 
					printer using the FOGRA39 dataset, which includes CMYK inputs and corresponding LAB color values. The techniques 
					compared include Distance-Weighted Interpolation, Nearest Neighbor Interpolation, Linear Interpolation, 2nd and 
					3rd Degree Polynomial Fitting, and an optimized Neural Network. The dataset was split into training and testing 
					sets, and each method was used to predict the LAB values for the test set, with accuracy measured by the mean 
					CIELAB color difference (ΔE). The results show that Linear Interpolation performed best with a mean ΔE of 0.14, 
					closely followed by 3rd Degree Polynomial Fitting with a mean ΔE of 0.62. Distance-Weighted Interpolation and 
					2nd Degree Polynomial Fitting also showed reasonable accuracy, with mean ΔE values of 2.28 and 1.83, respectively. 
					In contrast, the Nearest Neighbor Interpolation and the Neural Network methods yielded higher mean ΔE values of 3.97 
					and 3.95, respectively, indicating less accuracy. However, since this work was carried out using the characterization 
					dataset, the results can vary dramatically if real world color data is used. 

					</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/charac_printer.py" target="_blank">Source code</a> |
					    <a href="/musings/charac_printer.pdf" target="_blank">Mathematical background</a> 
					    
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/fitting.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Comparison of fitting techniques on color accuracy</figcaption>
					            </figure>
					        
					    </div>
					   
					</div>
					</div>
					<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>


				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>01.09.2024</b>: A 3D Color Gamut Viewer Application for Windows</h3>
				<div class="collapsible-content">
					<p align="justify">
					   An application that takes an image as input and displays the 3D color gamut of the colors in the image for Windows OS that I have developed in Python
					is presented here. The code takes in the RGB data converts them to LAB colors and plots them in the space. A convex hull 
					is used to compute the GBD. It also plots the convex hull surface by connecting the points in the LAB space. For 
					each triangle in the convex hull, the script plots a surface using the average RGB color of the triangle’s vertices.
					
					</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/gbd/color_gamut_viewer.py" target="_blank">Source code</a> |
					    <a href="/musings/gbd/color_gamut_viewer_app.pdf" target="_blank">Mathematical background</a> |
					    <a href="https://riptkolkata-my.sharepoint.com/:u:/g/personal/shankhya_riptkolkata_org/EaTFlEFB0VBOn16s603OpPUBfIv-Va9X27mD2wtHQCjVUA?e=XzaccD" target="_blank">Download the installer for the Color Gamut Viewer app</a> 
					
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/gbd/color_gamut_viewer_ss1.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Color Gamut Viewer application screenshot for Lena view 1</figcaption>
					            </figure>
					        
					    </div>
					    <div class="col-sm-6">
					        <figure>
					            <img src="musings/gbd/color_gamut_viewer_ss2.png" class="img-responsive img-rounded" alt="Image 4">
					            <figcaption style="text-align: center;">Color Gamut Viewer application screenshot for Lena view 2</figcaption>
					        </figure>
					    </div>
						
					</div>
					</div>
					<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>


				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>31.08.2024</b>: A simple amplitude modulated halftoning technique</h3>
				<div class="collapsible-content">
					<p align="justify">
					   This code implements the halftoning process, which has been adapted from this <a href="https://stackoverflow.com/questions/10572274/how-to-create-cmyk-halftone-images-from-a-color-image/10575940#10575940" target="_blank">source</a>. 
					The code is structured around a Python class called `HalftoneGenerator`, which  
					provides a method to convert an image into its halftone representation. Depending on the user’s preferences, the code can 
					generate either a grayscale or color halftone image. It processes each color channel (Cyan, Magenta, Yellow, and Black) 
					separately, applying a rotation to avoid visual artifacts and then calculating the size of the dots based on the average 
					intensity of the image in sampled regions. The code also offers flexibility in adjusting various parameters such as the 
					size of the sample boxes, the scaling factor for dot size, the percentage of gray component removal, and the format in 
					which the output images are saved. 
					</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/halftone.py" target="_blank">Source code</a> |
					    <a href="/musings/halftoning.pdf" target="_blank">Mathematical background</a> 
					    
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/lena.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Original image</figcaption>
					            </figure>
					        
					    </div>
					    <div class="col-sm-6">
					        <figure>
					            <img src="musings/lena_halftoned.png" class="img-responsive img-rounded" alt="Image 4">
					            <figcaption style="text-align: center;">Greyscale halftoned image</figcaption>
					        </figure>
					    </div>
						
					</div>

					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/lena_halftoned_c.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Cyan separation</figcaption>
					            </figure>
					        
					    </div>
					    <div class="col-sm-6">
    						<figure>
        					<img src="musings/lena_halftoned_m.png" class="img-responsive img-rounded" alt="Image 4" style="display: block; margin: 0 auto;">
        					<figcaption style="text-align: center; margin-top: 2px;">Magenta separation</figcaption>
    						</figure>
						</div>


						<div class="col-sm-6">
					        <figure>
					            <img src="musings/lena_halftoned_y.png" class="img-responsive img-rounded" alt="Image 4">
					            <figcaption style="text-align: center;">Yellow separation</figcaption>
					        </figure>
					    </div>
						<div class="col-sm-6">
					        <figure>
					            <img src="musings/lena_halftoned_k.png" class="img-responsive img-rounded" alt="Image 4">
					            <figcaption style="text-align: center;">Black separation</figcaption>
					        </figure>
					    </div>
					</div>

					</div>
					<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>


				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>30.08.2024</b>: Simple display class and output class ICC profiles using LCMS</h3>
				<div class="collapsible-content">
					<p align="justify">
					   Two C codes have been presented for the purpose of creating ICC profiles using the Little CMS (lcms) library, 
					focusing on both sRGB and CMYK color spaces. For the sRGB profile defines the D65 white point, defining sRGB primaries, 
					and tone reproduction curves (TRCs) specific to the sRGB color space. Other profile headers are also included such as the 
					profile version, device class, and manufacturer signature, as well as the key tags like the media white point and profile 
					description. The other code presents a method for creating a CMYK ICC profile for printers. The profile uses a transformation 
					pipelines using look-up tables (LUTs) for converting between the CMYK space and the Profile Connection Space (PCS). A random data 
					for the `AToB0` and `BToA0` tags due to the absence of real measurement data. The data obtained from the earlier post (ColorChecker) 
					for instance can be used to populate the A2B CLUT and the code will create the corresponding B2A CLUT. For simplicity only A2B0 CLUT
					have been presented in the code and that too represents an identify matrix. Both the codes use the lcms library's capabilities to create and manage ICC profiles.
					
					</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/profile/sRGB.c" target="_blank">Source code for sRGB profile</a> |
					    <a href="/profile/rgb_profile.pdf" target="_blank">Elaboration on the sRGB profile</a> |
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/profile/cmyk_profile.c" target="_blank">Source code for CMYK profile</a> |
					    <a href="/profile/cmyk_profile.pdf" target="_blank">Elaboration on the CMYK profile</a> |
					    <a href="https://littlecms.com/" target="_blank">Little CMS</a> |
					    <a href="https://www.color.org/profileinspector.xalter/" target="_blank">ICC Profile Inspector</a>
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="profile/srgb.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">sRGB profile viewed through ICC Profile Inspector</figcaption>
					            </figure>
					        
					    </div>
					    <div class="col-sm-6">
					        <figure>
					            <img src="profile/cmyk%20profile.png" class="img-responsive img-rounded" alt="Image 4">
					            <figcaption style="text-align: center;">CMYK profile viewed through ICC Profile Inspector</figcaption>
					        </figure>
					    </div>
						
					</div>
					</div>
					<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>


				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>25.08.2024</b>: A method for color test target generation and extraction of color values</h3>
				<div class="collapsible-content">
					<p align="justify">
					   A method is presented for generating a color test target based on user-defined LAB values and extracting RGB values from a scanned image of the target. 
						These processes involve color space transformations, perspective geometry, and statistical methods. The test target has been made in 
						accordance to the Gretag ColorChecker target. It contains 24 patches.
					</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/tar_gen/tar_gen.py" target="_blank">Source code for target generation</a> |
					    
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/tar_gen/read_tar.py" target="_blank">Source code for reading test target</a> |
					    <a href="/musings/tar_gen/tar_gen.pdf" target="_blank">Mathematical background on the process</a> 
						
						
					    				    
					
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/tar_gen/target.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Test target</figcaption>
					            </figure>
					        
					    </div>
					    <div class="col-sm-6">
					        <figure>
					            <img src="musings/tar_gen/debug_warped_image.png" class="img-responsive img-rounded" alt="Image 4">
					            <figcaption style="text-align: center;">Extraction of RGB values from identified segmented patches</figcaption>
					        </figure>
					    </div>
						
					</div>
					</div>
					<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>



				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>24.08.2024</b>: Implementation of an improved segment maxima based GBD and other GBD methods</h3>
				<div class="collapsible-content">
					<p align="justify">
					    Various methods for calculating Gamut Boundary Descriptors have been implemented. In an earlier post, I had
					presented a method for calculating GBD using segment maxima method, with enclosing surface covered by convex hull. 
						In this new method, I have used delaunay triangulation to enclose the surface using simplices. The gamut 
						surfaces have been colorized to depict their corresponding L*a*b* values, a wireframe gamut surface
						have also been presented. I have also plotted the gamut at constant L* values in the a*-b* plane. 
					Another approach have also been implemente, where a RBF has been used to compute and plot GBD of an image.
					Constrained Line Gamut Boundary (CLGB) and Flexible Sequential Gamut Boundary (FSLGB) have also been implemented
						from GBD obtained using segment maxima method.
					</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/gbd/single_slice.py" target="_blank">Source code for 2D GBD single slice</a> |
					    
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/gbd/multipl_slices.py" target="_blank">Source code for 2D GBD multiple slice</a> |
					    <a href="/musings/gbd/gamut_slices.pdf" target="_blank">Mathematical background on 2D GBD</a> |
						<a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/gbd/rbf_gbd.py" target="_blank">Source code for RBF based GBD</a> |
					    <a href="/musings/gbd/rbf.pdf" target="_blank">Mathematical background on RBF GBD</a> |
						<a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/gbd/smgbd_new.py" target="_blank">Source code for new SMGBD</a> |
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/gbd/smgbd_multiple.py" target="_blank">Source code for multiple views using SMGBD</a> |
					    <a href="/musings/gbd/smgbd_new.pdf" target="_blank">Mathematical background on new SMGBD</a> |
						<a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/gbd/clgb.py" target="_blank">Source code for CLGB</a> |
					    <a href="/musings/gbd/clgb.pdf" target="_blank">Mathematical background on CLGB</a> |
						<a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/gbd/flsgb.py" target="_blank">Source code for FLSGB</a> |
					    <a href="/musings/gbd/flsg.pdf" target="_blank">Mathematical background on FLSGB</a> 
						
					    				    
					
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/gbd/output_gamut_plot.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">2D GBD for constant L*</figcaption>
					            </figure>
					        
					    </div>
					    <div class="col-sm-6">
					        <figure>
					            <img src="musings/gbd/gamut_slices_output.png" class="img-responsive img-rounded" alt="Image 4">
					            <figcaption style="text-align: center;">Multiple 2D GBD for various L*</figcaption>
					        </figure>
					    </div>
						 <div class="col-sm-6">
					        <figure>
					            <img src="musings/gbd/gamut_rbf_output_optimized.png" class="img-responsive img-rounded" alt="Image 4">
					            <figcaption style="text-align: center;">RBF based GBD</figcaption>
					        </figure>
					    </div>
						
					</div>

					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/gbd/gbd_surface.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Improved SMGBD (solid)</figcaption>
					            </figure>
					        
					    </div>
					    <div class="col-sm-6">
					        <figure>
					            <img src="musings/gbd/gbd_wireframe_surface.png" class="img-responsive img-rounded" alt="Image 4">
					            <figcaption style="text-align: center;">Improved SMGBD (wireframe)</figcaption>
					        </figure>
					    </div>
						<div class="col-sm-6">
					        <figure>
					            <img src="musings/gbd/gbd_surface_multiple_views.png" class="img-responsive img-rounded" alt="Image 4">
					            <figcaption style="text-align: center;">Improved SMGBD (multiple views)</figcaption>
					        </figure>
					    </div>
					</div>

					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/gbd/clgb_gbd_hue_intersections.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">CLGBD</figcaption>
					            </figure>
					        
					    </div>
					    <div class="col-sm-6">
    						<figure>
        					<img src="musings/gbd/gamut_boundary_intersection.png" class="img-responsive img-rounded" alt="Image 4" style="display: block; margin: 0 auto;">
        					<figcaption style="text-align: center; margin-top: 2px;">FLSGBD</figcaption>
    						</figure>
						</div>


						<div class="col-sm-6">
					        <figure>
					            <img src="musings/gbd/multiple_gamut_boundaries_subplot.png" class="img-responsive img-rounded" alt="Image 4">
					            <figcaption style="text-align: center;">FLSGBD at various hue angles</figcaption>
					        </figure>
					    </div>
						
					</div>
				</div>
				<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>


				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>23.08.2024</b>: Implementation of Vividness-Preserved (VP) and Depth-Preserved (DP) Gamut Compression Algorithms</h3>
				<div class="collapsible-content">
					<p align="justify">
					    The Vividness-Preserved (VP) and Depth-Preserved (DP) Gamut Compression Algorithms are designed to compress the color 
					gamut of an image while preserving key perceptual attributes. Vividness-Preserved (VP) focuses on maintaining the vividness 
					or saturation of colors during the compression process. This is achieved by scaling both the lightness (L*) and chroma (C*) 
					of each color towards the black point (i.e., reducing their values proportionally), thereby compressing the color gamut into 
					the target space without significantly dulling the colors. The result is a more vibrant image, where the perceived intensity 
					and saturation of colors are preserved as much as possible within the limitations of the target gamut. Depth-Preserved (DP), 
					on the other hand, emphasizes preserving the perceived depth or contrast of the image. The DP method scales lightness towards 
					the cusp lightness (the brightest achievable lightness within the target gamut) while also proportionally scaling chroma. 
					This approach ensures that the contrast between different colors in the image is maintained, preventing the image from appearing 
					washed out or flat after gamut compression. The DP method is particularly useful in scenarios where maintaining the dynamic range 
					of the image is crucial.</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/vpdp.py" target="_blank">Source code</a> |
					    <a href="/musings/vpdp.pdf" target="_blank">Mathematical background</a> 
					    				    
					
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/vp_dp_images.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Comparison of mapped images against the original</figcaption>
					            </figure>
					        
					    </div>
					    <div class="col-sm-6">
					        <figure>
					            <img src="musings/vp_dp_gamuts.png" class="img-responsive img-rounded" alt="Image 4">
					            <figcaption style="text-align: center;">Comparison of gamuts of mapped images against the original</figcaption>
					        </figure>
					    </div>
					</div>
				</div>
				<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>


				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>23.08.2024</b>: Implementation of SGCK (Segmented Gamut Compression with Knee Scaling) Gamut Compression Algorithm</h3>
				<div class="collapsible-content">
					<p align="justify">
					    The SGCK (Segmented Gamut Compression with Knee Scaling) Gamut Compression Algorithm is designed to map colors from a 
					wide-gamut source to a narrower target gamut, while preserving perceptual color attributes like lightness 
					and chroma. An implementation of the same has been given. The process involves two main steps: non-linear lightness mapping and knee scaling. In the first step, the lightness 
					(L*) of each color is scaled, and if it exceeds a certain cusp lightness (representing the brightest color within the target gamut), 
					it is capped. In the second step, the chroma (C*) is proportionally scaled to compress the color gamut towards the target space 
					without significantly altering the hue. This approach aims to compress out-of-gamut colors smoothly into the target gamut while 
					minimizing perceptual distortion, thereby preserving the overall appearance of the image even after compression. The SGCK method 
					is effective in applications where maintaining the perceptual attributes of the image during gamut mapping is crucial.</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/sgck.py" target="_blank">Source code</a> |
					    <a href="/musings/sgck.pdf" target="_blank">Mathematical background</a> 
					    				    
					
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/image_sgck.jpg" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Original image (left) and mapped image (right)</figcaption>
					            </figure>
					        
					    </div>
					    <div class="col-sm-6">
					        <figure>
					            <img src="musings/gamut_sgck.png" class="img-responsive img-rounded" alt="Image 4">
					            <figcaption style="text-align: center;">Gamut along the L-C plane of original (left) and mapped (right) images</figcaption>
					        </figure>
					    </div>
					</div>
				</div>
				<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>


				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>22.08.2024</b>: Implementation of hue preserving minimum color difference gamut clipping (HPMINDE)</h3>
				<div class="collapsible-content">
					<p align="justify">
					    The Hue Preserving Minimum Color Difference (HPMINDE) process is a gamut mapping technique designed to map 
					colors from one color space, while preserving the hue and minimizing 
					perceptual color differences. An implementation has been presented that converts an image from sRGB to the CIELAB color space, 
					known for its perceptual uniformity. The AdobeRGB gamut is defined by generating LAB points using an ICC profile, 
					and a convex hull is constructed to represent the Gamut Boundary Descriptor (GBD). The HPMINDE algorithm then maps 
					each color in the image to the closest point on the GBD, ensuring hue preservation and minimizing the weighted color 
					difference, which includes differences in lightness, chroma, and hue angle. The resulting mapped image is compared to 
					the original, showing that while the colors are adjusted to fit within the AdobeRGB gamut, the perceptual differences 
					are minimized, and the hue is well-preserved. The method is effective but can be computationally intensive due to the 
					point-by-point comparison required to maintain the hue and minimize color differences. Due to this, a compressed version 
					of the image has been used for mapping purpose. The results are evident from the gamuts given below.</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/hpminde.py" target="_blank">Source code</a> |
					    <a href="/musings/hpminde.pdf" target="_blank">Mathematical background</a> 
					    				    
					
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/hpmin_de_image_comparison_optimized.jpg" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Original image (left) and mapped image (right)</figcaption>
					            </figure>
					        
					    </div>
					    <div class="col-sm-6">
					        <figure>
					            <img src="musings/gamut_lc_comparison_hpmin_de_optimized.png" class="img-responsive img-rounded" alt="Image 4">
					            <figcaption style="text-align: center;">Gamut along the L-C plane of original (left) and mapped (right) images</figcaption>
					        </figure>
					    </div>
					</div>
				</div>
				<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>


				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>22.08.2024</b>: Implementation of various gamut clipping algorithms</h3>
				<div class="collapsible-content">
					<p align="justify">
					An implementation and analysis of three gamut clipping techniques: SCLIP (Spherical CLIP), CCLIP (Chroma CLIP), and LCLIP (Lightness CLIP) has been presented. Each method is designed to map out-of-gamut (OOG) colors into a target color space, specifically AdobeRGB, using different approaches to preserve certain aspects of the image's color quality. SCLIP preserves color balance by mapping colors towards a reference lightness, usually, which minimally alters color but maintains the overall look of the scene. CCLIP focuses on reducing chroma to bring colors within the target gamut, resulting in an image with lower saturation and more muted colors. LCLIP reduces the lightness of OOG colors, leading to darker tones and reduced brightness, particularly affecting the highlights and midtones.</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/sclip.py" target="_blank">Source code</a> |
					    <a href="/musings/sclip.pdf" target="_blank">Mathematical background</a> 
					    				    
					
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
						    <figure>
					            <img src="musings/image_comparison_annotated.jpg" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Comparison of clipped images with the original</figcaption>
					            </figure>
					        
					    </div>
					    <div class="col-sm-6">
					        <figure>
					            <img src="musings/gamut_lc_comparison_all_clips.png" class="img-responsive img-rounded" alt="Image 4">
					            <figcaption style="text-align: center;">Comparison of gamuts of mapped images against original</figcaption>
					        </figure>
					    </div>
					</div>
				</div>
				<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>


				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>22.08.2024</b>: Minimum Color Difference Gamut Clipping</h3>
				<div class="collapsible-content">
					<p align="justify">
					    An implementation of the Minimum Color Difference Gamut Clipping method, used for mapping colors from an input gamut (e.g., sRGB) to a target gamut (e.g., AdobeRGB) has been presented. A function is introduced that generates a representative sampling of the the AdobeRGB color space using the ICC profile. The resulting points is used to generate a Gamut Boundary Descriptor (GBD) for the AdobeRGB space. Out-of-gamut colors are mapped to the closest boundary point on the target gamut by minimizing the Euclidean distance in CIELAB space. Some shortcomings of the method include, reduced contrast, diminished colorfulness, and a loss of detail in the mapped images.</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/min_de_gm.py" target="_blank">Source code for SMBGD</a> |
					    <a href="/musings/min_de_mapping.pdf" target="_blank">Mathematical background</a> 					    
					
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
					        <figure>
					            <img src="musings/image_comparison.png" class="img-responsive img-rounded" alt="Image 4">
					            <figcaption style="text-align: center;">Original image (left) and mapped image (right)</figcaption>
					        </figure>
					    </div>
					    <div class="col-sm-6">
					        <figure>
					            <img src="musings/gamut_comparison.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Comparison of gamut in LAB space</figcaption>
					        </figure>
					    </div>
						<div class="col-sm-6">
					        <figure>
					            <img src="musings/gamut_lc_comparison.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Comparison of gamut along a plane of constant hue in L-C space</figcaption>
					        </figure>
					    </div>
					</div>
				</div>
				<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>
				

				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>21.08.2024</b>: Gamut Boundary Descriptor</h3>
				<div class="collapsible-content">
					<p align="justify">
					    A comparison has been drawn between the gamuts obtained from GBD calculated using convex hull method 
					and segment maxima method. SMGBD results is more smoother gamut surface.</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/smgbd.py" target="_blank">Source code for SMBGD</a> |
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/gbd_convex_hull.py" target="_blank">Source Code for convex hull GBD</a> |
					    <a href="/musings/SMGBD.pdf" target="_blank">Mathematical background</a> 					    
					
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
					        <figure>
					            <img src="musings/sample.jpg" class="img-responsive img-rounded" alt="Image 4">
					            <figcaption style="text-align: center;">Image under consideration</figcaption>
					        </figure>
					    </div>
					    <div class="col-sm-6">
					        <figure>
					            <img src="musings/SMGBD%20with%20convex%20hull.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">SMGBD with convex hull</figcaption>
					        </figure>
					    </div>
						<div class="col-sm-6">
					        <figure>
					            <img src="musings/output_plot.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">GBD using convex hull</figcaption>
					        </figure>
					    </div>
					</div>
				</div>
				<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>
				
				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>18.08.2024</b>: Plotting FOGRA39 dataset in CIELAB space</h3>
				<div class="collapsible-content">
					<p align="justify">
					    Created this Python script that creates a 3D scatter plot to visualize LAB color space data from the FOGRA39 characterization dataset. The points are color-coded according to their RGB values and annotated with hover text displaying their LAB values. The script also draws black axis lines to help orient the viewer in the LAB color space.
					</p>
					<span class="course-links">
					    <a href="/musings/3d_scatter_lab.html" target="_blank">Plot</a> |
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/3d_lab_plot.py" target="_blank">Source Code</a> |
					    <a href="https://www.color.org/fogra39.xalter" target="_blank">More on FOGRA39 dataset</a> 
					</span>
				
				</div>
				<!--button class="see-more-btn" onclick="toggleContent(this)">See more...</button--->
				
				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>20.06.2024</b>: Review on use of computational intelligence in research on printing technology</h3>
				<div class="collapsible-content">
					<p align="justify">
					    A review on the application of computational intelligence (CI) techniques in the field of printing technology, highlighting how methods such as neural networks, fuzzy logic, evolutionary algorithms, and swarm intelligence have transformed various processes within this domain.
					</p>
					<span class="course-links">
					    <a href="/musings/plot1.html" target="_blank">Interactive plot</a> |
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/paper_plot.py" target="_blank">Source Code</a> 
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-6">
					        <figure>
					            <img src="musings/Number of Publications per Category (1).png" class="img-responsive img-rounded" alt="Image 4">
					            <figcaption style="text-align: center;">Category wise publications</figcaption>
					        </figure>
					    </div>
					    <div class="col-sm-6">
					        <figure>
					            <img src="musings/Number of Publications per Year.png" class="img-responsive img-rounded" alt="Image 5">
					            <figcaption style="text-align: center;">Year wise publications</figcaption>
					        </figure>
					    </div>
					</div>
				</div>
				<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>

				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>17.01.2024</b>: A simple image conversion pipeline</h3>
				<div class="collapsible-content">
					<p align="justify">
					    The color_conversion_pipeline repository offers a comprehensive Python-based solution for managing color conversions across various spaces. The workflow is structured into multiple steps, each handled by a distinct Python script, beginning with the extraction of RGB values and their conversion to CMYK.
					</p>
					<span class="course-links">
					    <a href="musings/color_conv_workflow.pdf" target="_blank">Workflow</a> |
					    <a href="https://github.com/shankhya/color_conversion_pipeline" target="_blank">Source Code</a> |
					    <a href="http://www.brucelindbloom.com/index.html" target="_blank">Color equations used</a> 
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-4">
					        <figure>
					            <img src="musings/GCR Colorimetric.png" class="img-responsive img-rounded" alt="Image 1">
					            <figcaption style="text-align: center;">Comparison of images before and after conversion obtained from mathematical L*a*b* to XYZ colorimetric &#916;E<sub>76</sub> = 18.16</figcaption>
					        </figure>
					    </div>
					    <div class="col-sm-4">
					       
					        <figure>
					            <img src="musings/GCR LUT.png" class="img-responsive img-rounded" alt="Image 2">
					            <figcaption style="text-align: center;">Comparison of images before and after conversion obtained from L*a*b* to XYZ using LUT &#916;E<sub>76</sub> = 77.81</figcaption>
					        </figure>
					    </div>
					    <div class="col-sm-4" style="display: flex; align-items: center;">
					        <figure>
					            <img src="musings/No GCR.png" class="img-responsive img-rounded" alt="Image 3">
					            <figcaption style="text-align: center;">Comparison of color difference between original RGB image and CMY images converted using colorimetric and LUT based technique</figcaption>
					        </figure>
					    </div>
					</div>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-4">
					        <figure>
					            <img src="musings/delta e colorimetric.png" class="img-responsive img-rounded" alt="Image 6">
					            <figcaption style="text-align: center;">Comparison of color difference between colorimetric converted images for various black generation techniques</figcaption>
					        </figure>
					    </div>
					    <div class="col-sm-4">
					        <figure>
					            <img src="musings/delta e lut.png" class="img-responsive img-rounded" alt="Image 7">
					            <figcaption style="text-align: center;">Comparison of color difference between images converted using LUT for various black generation techniques</figcaption>
					        </figure>
					    </div>
					</div>
				</div>
				<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>

				
				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>25.09.2023</b>: Plotting the gamut of an electrophotographic printer using uncoated media</h3>
				<div class="collapsible-content">
					<p align="justify">
					Color patches varying in tonal values i.e., 25%, 50%, 75%, 100% for Cyan, Magenta, Yellow, Red, Green and Blue were printed on uncoated media 
						containing OBA. They were measured using a spectroradiometer using D65 illuminant. Tristimulus values of color patches were
						obtained from their spectral data (considering CIE 1931 CMFs). The chromaticities were then plotted on the CIE 1931 chromaticity space
						(using the colour.plotting function from colour-science) and 3rd degree polynomial fitting was used to fit the data. The gamut boundary was obtained by joining the chromaticities of all colors having
						the highest saturation.
					</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/gamut_plot.py" target="_blank">Source Code</a> |
					    <a href="https://colour.readthedocs.io/en/latest/colour.plotting.html#" target="_blank">colour.plotting</a> 
					    
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-4">
					        <figure>
					            <img src="musings/myplot1.png" class="img-responsive img-rounded" alt="Image 6">
					            <figcaption style="text-align: center;">Gamut of an electrophotographic printer and uncoated media pair</figcaption>
					        </figure>
					    </div>
					    
					</div>
				</div>
				<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>

				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>30.08.2023</b>: Plotting on the CIE 1931 Chromaticity Diagram</h3>
				<div class="collapsible-content">
					<p align="justify">
					The colour-science package for Python can be used to plot various colors on the CIE 1931 Chromaticity Diagram. The package provides a wide range of 
						colorimetric functionalities including color algebra, plotting tools, etc. In this example, two colors having chromaticity coordinates have been plotted
						with respect to perfect white point and their dominant wavelengths have been calculated using the in-built function and that too have been plotted.
					</p>
					<span class="course-links">
					    <a href="https://raw.githubusercontent.com/shankhya/shankhya.github.io/main/musings/plot_dom_wav.py" target="_blank">Source Code</a> |
					    <a href="https://colour.readthedocs.io/en/latest/generated/colour.dominant_wavelength.html" target="_blank">colour.dominant_wavelength</a> 
					    
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-4">
					        <figure>
					            <img src="musings/dom.png" class="img-responsive img-rounded" alt="Image 6">
					            <figcaption style="text-align: center;">Dominant wavelength of two colors plotted in the CIE chromaticity space</figcaption>
					        </figure>
					    </div>
					    
					</div>
				</div>
				<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>

				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>19.12.2020</b>: A method for converting a scanner to colorimeter</h3>
				<div class="collapsible-content">
					<p align="justify">
					A method is proposed here to use a standard scanner as a colorimeter by converting RGB values to XYZ values. This alternative approach is explored due to the unavailability of spectrophotometers, which are traditionally used for accurate color measurement. 
						The method involves using a transformation matrix derived from data collected using a test target, with further accuracy improvements through polynomial color correction techniques. While this method is not a replacement for industry-grade equipment, 
						it offers a cost-effective solution for educational purposes in practical color science.</p>
					<span class="course-links">
					    <a href="/musings/scanner_as_colorimeter.pdf" target="_blank">Document</a> 
					    
					</span>
					
				</div>
				<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>

				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>20.10.2020</b>: Developing a DIY spectrometer using OSS tools</h3>
				<div class="collapsible-content">
					<p align="justify">
					    The project was initiated after attempts to procure a spectrophotometer and convert a desktop scanner into a colorimeter yielded limited success. Given my aim to develop color measurement and management tools using FOSS alternatives, and after quickly realizing the scanner can not really work as true spectrometer even if it characterized to behave as one due to a wide variety of reasons, I started reading on the possibility of developing a DIY spectrometer using OSS tools. I came across multiple sources <a href="https://www.instructables.com/A-Homemade-Webcam-spectrometer-for-Emission-and-Ab/" target="_blank">Source 1</a>, <a href="https://physicsopenlab.org/2015/11/26/webcam-diffraction-grating-spectrometer/" target="_blank">Source 2</a>, <a href="https://pubs.acs.org/doi/epdf/10.1021/acs.jchemed.0c01085" target="_blank">Source 3</a>, that helped me in ideating the process. I created a simple design with materials easily available at home and started developing the instrument. I got some valuable suggestions from a few good subject experts along the way. I used the Theremino Spectrometer software for obtaining the spectral data and plotting them.  The DIY spectrometer is intended to capture Spectral Power Distributions (SPDs) of colorants using a tungsten filament light source, aiming to demonstrate color as measurable data and potentially use these measurements for printer characterization with ArgyllCMS. Given the limitations in resources and knowledge, I primarily sought to develop a proof-of-concept that can provide students with hands-on experience in color science. 
					</p>	
					<span class="course-links">
					    <a href="/musings/Final Design Spectro.pdf" target="_blank">The schematic of the instrument</a> |
					    <a href="https://physicsopenlab.org/2015/11/26/webcam-diffraction-grating-spectrometer/" target="_blank">Sources of information</a> |
					    <a href="https://www.theremino.com/downloads/automation#spectrometer" target="_blank">Theremino Spectrometer</a> |
					    <a href="/musings/SpectrumFile_001.txt" target="_blank">Raw spectral data of a sample measured by the spectrometer</a> 
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-4">
					        <figure>
					            <img src="https://shankhya.github.io/musings/DIY%20Spectrometer%20setup%201.jpg" class="img-responsive img-rounded" alt="Image 6">
					            <figcaption style="text-align: center;">Setup of the spectrometer</figcaption>
					        </figure>
					    </div>
					    <div class="col-sm-4">
					        <figure>
					            <img src="https://shankhya.github.io/musings/DIY%20Spectrometer%20setup%202.jpg" class="img-responsive img-rounded" alt="Image 7">
					            <figcaption style="text-align: center;">Color Checker target.</figcaption>
					        </figure>
					    </div>
						<div class="col-sm-4">
					        <figure>
					            <img src="https://shankhya.github.io/musings/DIY%20Spectrometer%20setup%203.jpg" class="img-responsive img-rounded" alt="Image 7">
					            <figcaption style="text-align: center;">Reflection spectrum captured by the Theremino Spectrometer software.</figcaption>
					        </figure>
					    	</div>
						<div class="col-sm-4">
					        <figure>
					            <img src="musings/0_07.png" class="img-responsive img-rounded" alt="Image 7">
					            <figcaption style="text-align: center;">Spectrum of a sample obtained from the spectrometer.</figcaption>
					        </figure>
					    	</div>
					</div>
				</div>
				<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>

				<h3><i class="fa fa-bell" aria-hidden="true"></i> <b>10.11.2019</b>: Creating a color management laboratory using FOSS</h3>
				<div class="collapsible-content">
					<p align="justify">
					    In 2019, I started my journey on creating a complete color management laboratory without any proprietary hardware or software, but only using FOSS tools for the color technology laboratory course and other elective courses I teach at the institute. I document my initiative, the motivations, the hindrances and the solutions implemented in setting up of the lab. The lab was established using accessible open-source software, like ArgyllCMS and LittleCMS, in combination with basic hardware such as desktop printers and scanners. The document discusses the technical challenges faced, the solutions devised to overcome these challenges, and the significant learning curve involved in implementing these systems. It also reflects on the broader impact of the open-source movement on education and research, advocating for the use of free and open-source software to democratize access to advanced color management tools. The lab aims to provide students with practical experience in managing color workflows, ultimately enhancing their employability in the printing industry.</p>
					<span class="course-links">
					    <a href="/musings/creating_the_color_lab.pdf" target="_blank">Read the journey here</a> |
					    <a href="https://argyllcms.com/" target="_blank">ArgyllCMS</a> |
					    <a href="https://lprof.sourceforge.net/" target="_blank">LProf</a> 
					</span>
					<!-- Images related to this section -->
					<div class="row" style="padding: 2%; display: flex; align-items: center;">
					    <div class="col-sm-4">
					        <figure>
					            <img src="musings/IMG_20200205_183331.jpg" class="img-responsive img-rounded" alt="Image 6">
					            <figcaption style="text-align: center;">A DYI light booth with incandescent illuminant</figcaption>
					        </figure>
					    </div>
					    <div class="col-sm-4">
					        <figure>
					            <img src="musings/IMG_20200206_144144.jpg" class="img-responsive img-rounded" alt="Image 7">
					            <figcaption style="text-align: center;">The very first setup of the lab using a single PC, desktop scanner and inkjet printer.</figcaption>
					        </figure>
					    </div>
					</div>
				</div>
				<button class="see-more-btn" onclick="toggleContent(this)">See more...</button>
			</div>
		</div>		
	</div>

	<div class="footer">
    <p>Last updated: <script>document.write(new Date(document.lastModified).toLocaleDateString());</script></p>

    <p>All rights reserved. Shankhya Debnath 2025.</p>
	</div>

	<script>
		$('#news').load('news.html');
	</script>

</body>
</html>

